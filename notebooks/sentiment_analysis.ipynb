{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce40dc4",
   "metadata": {},
   "source": [
    "### Import some system libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import plotly.subplots as sp\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94997b",
   "metadata": {},
   "source": [
    "#### Load the dataset using the local .env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../scripts/')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from load_data import load_csv\n",
    "load_dotenv()\n",
    "finance_data = os.getenv('FINANCIAL_NEWS')\n",
    "apple_data = os.getenv('APPLE_STOCK')\n",
    "amazon_data = os.getenv('AMAZON_STOCK')\n",
    "google_data = os.getenv('GOOGLE_STOCK')\n",
    "meta_data = os.getenv('META_STOCK')\n",
    "microsoft_data = os.getenv('MICROSOFT_STOCK')\n",
    "nvdia_data = os.getenv('NVIDIA_STOCK')\n",
    "tesla_data = os.getenv('TESLA_STOCK')\n",
    "\n",
    "finance_df = load_csv(finance_data)\n",
    "apple_data_df = load_csv(apple_data)\n",
    "amazon_data_df = load_csv(amazon_data)\n",
    "google_data_df = load_csv(google_data)\n",
    "meta_data_df = load_csv(meta_data)\n",
    "microsoft_data_df = load_csv(microsoft_data)\n",
    "nvdia_data_df = load_csv(nvdia_data)\n",
    "tesla_data_df = load_csv(tesla_data)\n",
    "if finance_df is not None and apple_data_df is not None and amazon_data_df is not None and google_data_df is not None and meta_data_df is not None and microsoft_data_df is not None and nvdia_data_df is not None and tesla_data_df is not None:\n",
    "    print(f\"Data loaded successfully with {len(finance_df)} records.\")\n",
    "    print(f\"Data loaded successfully with {len(apple_data_df)} Apple records.\")\n",
    "    print(f\"Data loaded successfully with {len(amazon_data_df)} Amazon records.\")\n",
    "    print(f\"Data loaded successfully with {len(google_data_df)} Google records.\")\n",
    "    print(f\"Data loaded successfully with {len(meta_data_df)} Meta records.\")\n",
    "    print(f\"Data loaded successfully with {len(microsoft_data_df)} Microsoft records.\")\n",
    "    print(f\"Data loaded successfully with {len(nvdia_data_df)} NVDIA records.\")\n",
    "    print(f\"Data loaded successfully with {len(tesla_data_df)} TESLA records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Financial News Data:')\n",
    "print(finance_df.head())\n",
    "print(finance_df.columns)\n",
    "print(finance_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f5345",
   "metadata": {},
   "source": [
    "### Descriptive Statistics on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_lengths = finance_df['headline'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03594f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins and labels\n",
    "bins = [0, 100, 200, float('inf')]\n",
    "labels = ['0-100', '100-200', '>200']\n",
    "headline_bins = pd.cut(headline_lengths, bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Count headlines per bin\n",
    "bin_counts = headline_bins.value_counts().sort_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(bin_counts.index, bin_counts.values, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add counts on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f'{int(height)}',\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=11,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.title('Distribution of Headline Lengths')\n",
    "plt.xlabel('Headline Length (Characters)')\n",
    "plt.ylabel('Number of Headlines')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f374d1",
   "metadata": {},
   "source": [
    "Most of the length of headlines fall between 0 - 100 which is **1,180,836**, and the second is 100 - 200 is **191690** and only few more than 200 is **34802**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d897873",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abadf339",
   "metadata": {},
   "outputs": [],
   "source": [
    "## show minimum headline length\n",
    "finance_df['headline_length'] = finance_df['headline'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aee166",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df['headline_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df['headline_length'].hist(bins=50, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9972071",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(finance_df['headline_length'].describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(finance_df, x='headline_length', nbins=30, title='Distribution of Headline Lengths')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76117ee1",
   "metadata": {},
   "source": [
    "##### Let us count the number of articles published per date in which date the articles where published most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67012de",
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_counts_per_date = finance_df['date'].value_counts()\n",
    "\n",
    "publisher_counts_per_date = publisher_counts_per_date.sort_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "publisher_counts_per_date.plot(kind='line', marker='o')\n",
    "plt.title(\"Publisher Counts Per Date\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb61064",
   "metadata": {},
   "source": [
    "##### Let us count the number of articles per publisher which is to identify which publishers are most active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of articles per publisher\n",
    "publisher_count = finance_df['publisher'].value_counts()\n",
    "\n",
    "fig = px.bar(publisher_count, x=publisher_count.index, y=publisher_count.values, height=2000,\n",
    "               labels={'x': 'Publisher', 'y': 'Number of Articles'},\n",
    "               title='Number of Articles per Publisher')\n",
    "fig.update_layout(xaxis={\"categoryorder\": \"total descending\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f91b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### publication dates to see trends over time\n",
    "finance_df['date'] = pd.to_datetime(finance_df['date'], format='ISO8601', utc=True)\n",
    "finance_df['date_x'] = finance_df['date'].dt.date\n",
    "finance_df['date_x'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939db972",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df['date_x'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad8359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finance_df['date'].head())\n",
    "print(finance_df['date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef03f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0449f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fe7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df[finance_df['stock']=='AAPL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ab5380",
   "metadata": {},
   "source": [
    "#### Text Analysis (Sentiment analysis and Topic modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentimental_analysis import get_sentiment_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Apple Stock data\")\n",
    "print(apple_data_df.head())\n",
    "print(\"Amazon Stock data\")\n",
    "print(amazon_data_df.head())\n",
    "print(\"Google Stock data\")\n",
    "print(google_data_df.head())\n",
    "print(\"Meta Stock data\")\n",
    "print(meta_data_df.head())\n",
    "print(\"Microsoft Stock data\")\n",
    "print(microsoft_data_df.head())\n",
    "print(\"Nvdia Stock data\")\n",
    "print(nvdia_data_df.head())\n",
    "print(\"Tesla Stock data\")\n",
    "print(tesla_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933efdf7",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f321c0",
   "metadata": {},
   "source": [
    "#### Filter data frame for only the main stock names apple, microsoft, google, amazon, TESLA, Meta, NVDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_stocks = ['AAPL', 'MSF', 'GOOG', 'AMZN', 'TSLA', 'FB', 'NVDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = finance_df[finance_df['stock'].isin(target_stocks)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9520471",
   "metadata": {},
   "source": [
    "### Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3fd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "filtered_df['headline'] = filtered_df.apply(lambda row: row['headline'].lower(),axis=1) #removed capitalisation\n",
    "filtered_df['headline'] = filtered_df.apply(lambda row: re.sub(\"@[A-Za-z0-9_]+\",\"\", row['headline']),axis=1) #removed mentions\n",
    "filtered_df['headline'] = filtered_df.apply(lambda row: re.sub(\"#[A-Za-z0-9_]+\",\"\", row['headline']),axis=1) #removed hashtags\n",
    "filtered_df['headline'] = filtered_df.apply(lambda row: re.sub(r\"http\\S+\",\"\", row['headline']),axis=1) #removed websites\n",
    "filtered_df['headline'] = filtered_df.apply(lambda row: re.sub(r\"www.\\S+\",\"\", row['headline']),axis=1)\n",
    "filtered_df['headline'] = filtered_df.apply(lambda row: re.sub('[()!?]',\" \", row['headline']),axis=1) #removed puncs\n",
    "filtered_df['headline'] = filtered_df.apply(lambda row: re.sub('\\[.*?\\]',\" \", row['headline']),axis=1) \n",
    "filtered_df['headline'] = filtered_df.apply(lambda row: re.sub(\"[^a-z]\",\" \", row['headline']),axis=1)\n",
    "\n",
    "filtered_df[['headline']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_df['Sentiment'] = filtered_df['headline'].apply(lambda x : get_sentiment_word(x))\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be769167",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[filtered_df[\"stock\"]==\"AAPL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bb494",
   "metadata": {},
   "source": [
    "Now we need to create posetive, negative, neutral for polarity of sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb912655",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['sentiment_score_word'] = filtered_df['Sentiment'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def1391",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93916eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_count = (filtered_df['sentiment_score_word']=='Negative').sum()\n",
    "positive_count = (filtered_df['sentiment_score_word']=='Positive').sum()\n",
    "neutral_count = (filtered_df['sentiment_score_word']=='Neutral').sum()\n",
    "print(f\"Negative: {negative_count}, Positive: {positive_count}, Neutral: {neutral_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentimental_analysis import articles_sentiment_analysis\n",
    "articles_sentiment_analysis(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_count = (filtered_df['Sentiment'] > 0).sum()  # count positive values\n",
    "negative_count = (filtered_df['Sentiment'] < 0).sum()  # count negative values\n",
    "zero_count = (filtered_df['Sentiment'] == 0).sum()  # count zero values\n",
    "\n",
    "# display counts\n",
    "print(\"Positive Count:\", positive_count)\n",
    "print(\"Negative Count:\", negative_count)\n",
    "print(\"Neutral Count:\", zero_count)\n",
    "\n",
    "labels = ['Positive', 'Negative' , 'Neutral']\n",
    "sizes = [positive_count, negative_count, zero_count]\n",
    "colors = ['g', 'r', 'y' ]  \n",
    "\n",
    "# pie chart\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.axis('equal')\n",
    "plt.title('Distribution of Positive and Negative')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe96f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.groupby('date')['Sentiment'].mean().plot(figsize=(20,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205dde4",
   "metadata": {},
   "source": [
    "##### Number of Published articles wrt sentiment categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8afe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_Categories=filtered_df['sentiment_score_word'].value_counts()\n",
    "print(sentiment_Categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170a4dd8",
   "metadata": {},
   "source": [
    "##### Categorize Sentiment by pecentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef35e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_Of_Sentiment=filtered_df['sentiment_score_word'].shape\n",
    "\n",
    "number_Of_Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_Of_Sentiment=filtered_df['sentiment_score_word'].shape\n",
    "percentage_Of_Categories = np.round((sentiment_Categories/number_Of_Sentiment)*100,2)\n",
    "percentage_Of_Categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501de8dc",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b44905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime for analysis\n",
    "#filtered_df['date'] = pd.to_datetime(filtered_df['date'], errors='coerce')\n",
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1597abc",
   "metadata": {},
   "source": [
    "#### Publication Frequency Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by date and count the number of publications\n",
    "#filtered_df['date'] = pd.to_datetime(filtered_df['date'], errors='coerce')\n",
    "filtered_df['publication_date'] = filtered_df['date'].dt.date\n",
    "daily_counts = filtered_df.groupby('publication_date').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374be96e",
   "metadata": {},
   "source": [
    "##### Plot daily publication frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b58522",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "daily_counts.plot(kind='line', marker='o', color='red')\n",
    "plt.title('Publication Frequency Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e1c42",
   "metadata": {},
   "source": [
    "##### Number of Publication per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Publishing Times Analysis ###\n",
    "# Extract hour from the `date` column\n",
    "filtered_df['publication_hour'] = filtered_df['date'].dt.hour\n",
    "\n",
    "# Count the number of publications by hour\n",
    "hourly_counts = filtered_df['publication_hour'].value_counts().sort_index()\n",
    "hourly_counts.index.name = None  # Remove index name to avoid MultiIndex\n",
    "hourly_counts.name = 'count'     # Optional: set the Series name\n",
    "\n",
    "\n",
    "# Plot publishing times\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "hourly_counts.plot(kind='bar', color='skyblue')\n",
    "plt.yscale('log')  # 👈 Use log scale\n",
    "plt.title('Publication Frequency by Hour (Log Scale)')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Number of Articles (log scale)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e5a1f7",
   "metadata": {},
   "source": [
    "### Analysis on Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_counts = filtered_df['publisher'].value_counts()\n",
    "print(\"Top 10 Publishers by Article Count:\")\n",
    "print(publisher_counts.head(10))\n",
    "print(\"\\nLast 10 Publishers by Article Count:\")\n",
    "print(publisher_counts.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0d5b0",
   "metadata": {},
   "source": [
    "### Sentiment analysis for publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentimental_analysis import get_sentiment_analysis_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e424f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment_analysis_publisher(filtered_df,'Benzinga Newsdesk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Publishers Contribution ###\n",
    "# Count articles per publisher\n",
    "publisher_counts = filtered_df['publisher'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d92c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot publisher contribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=publisher_counts.values, y=publisher_counts.index, palette=\"magma\")\n",
    "plt.title(\"Publisher Contribution to the News Feed\")\n",
    "plt.xlabel(\"Number of Articles\")\n",
    "plt.ylabel(\"Publisher\")\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract Unique Domains from Email Addresses ###\n",
    "# Identify if a publisher name is an email address\n",
    "filtered_df['is_email'] = filtered_df['publisher'].str.contains('@')\n",
    "\n",
    "# Extract domain from email addresses\n",
    "filtered_df['domain'] = filtered_df['publisher'].apply(\n",
    "    lambda x: x.split('@')[1] if '@' in x else None\n",
    ")\n",
    "\n",
    "# Count the number of articles by domain\n",
    "domain_counts = filtered_df['domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65397ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(domain_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef781266",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv(\"../data/processed/filtered__news_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
